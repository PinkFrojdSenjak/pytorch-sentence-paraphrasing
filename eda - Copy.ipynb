{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "import torch\r\n",
                "import numpy as np\r\n",
                "from torch import nn\r\n",
                "import pandas as pd\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "from transformers import BertTokenizerFast\r\n",
                "from sklearn.model_selection import train_test_split"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "df = pd.read_csv('train.csv')\r\n",
                "df =df.dropna()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "train_old, temp_old, train_new, temp_new = train_test_split(df['old'], df['new'], \r\n",
                "                                                                    random_state=2018, \r\n",
                "                                                                    test_size=0.3)\r\n",
                "val_old, test_old, val_new, test_new = train_test_split(temp_old, temp_new, \r\n",
                "                                                                random_state=2018, \r\n",
                "                                                                test_size=0.5) "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "device = torch.device('cpu')\r\n",
                "if torch.cuda.is_available():\r\n",
                "    device = torch.device(\"cuda\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "source": [
                "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "source": [
                "seq_len = [len(str(i).split()) for i in train_old]\r\n",
                "pd.Series(seq_len).plot.hist(bins = 30).plot()\r\n",
                "plt.show()"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ],
                        "image/png": "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"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Tokens for training and validation"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "from torchtext.datasets import WikiText2\r\n",
                "from torchtext.data.utils import get_tokenizer\r\n",
                "from torchtext.vocab import build_vocab_from_iterator\r\n",
                "\r\n",
                "train_iter = WikiText2(split='train')\r\n",
                "tokenizer = get_tokenizer('basic_english')\r\n",
                "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\r\n",
                "vocab.set_default_index(vocab['<unk>']) "
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "c:\\Users\\psiml\\Documents\\projekat\\.data\\WikiText2\\wikitext-2-v1.zip: 100%|██████████| 4.48M/4.48M [00:00<00:00, 6.59MB/s]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "len(vocab)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "28782"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 5
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "source": [
                "oldTrainTokens = tokenizer.batch_encode_plus(\r\n",
                "    train_old.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "newTrainTokens = tokenizer.batch_encode_plus(\r\n",
                "    train_new.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "oldValTokens = tokenizer.batch_encode_plus(\r\n",
                "    val_old.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "newValTokens = tokenizer.batch_encode_plus(\r\n",
                "    val_new.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "\r\n",
                "oldTestTokens = tokenizer.batch_encode_plus(\r\n",
                "    test_old.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "newTestTokens = tokenizer.batch_encode_plus(\r\n",
                "    test_new.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "source": [
                "totensor = torch.tensor(oldTrainTokens['input_ids'])\r\n",
                "tntensor = torch.tensor(newTrainTokens['input_ids'])\r\n",
                "\r\n",
                "tomask = torch.tensor(oldTrainTokens['attention_mask'])\r\n",
                "tnmask = torch.tensor(newTrainTokens['attention_mask'])\r\n",
                "\r\n",
                "votensor = torch.tensor(oldValTokens['input_ids'])\r\n",
                "vntensor = torch.tensor(newValTokens['input_ids'])\r\n",
                "\r\n",
                "vomask = torch.tensor(oldValTokens['attention_mask'])\r\n",
                "vnmask = torch.tensor(newValTokens['attention_mask'])\r\n",
                "\r\n",
                "testotensor = torch.tensor(oldTestTokens['input_ids'])\r\n",
                "testntensor = torch.tensor(newTestTokens['input_ids'])\r\n",
                "\r\n",
                "testomask = torch.tensor(oldTestTokens['attention_mask'])\r\n",
                "testnmask = torch.tensor(newTestTokens['attention_mask'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "source": [
                "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
                "batch_size = 32\r\n",
                "trainData = TensorDataset(totensor, tntensor, tomask, tnmask)\r\n",
                "valData = TensorDataset(votensor, vntensor, vomask, vnmask)\r\n",
                "testData = TensorDataset(testotensor, testntensor, testomask, testnmask)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "source": [
                "trainSampler = RandomSampler(trainData)\r\n",
                "valSampler = RandomSampler(valData)\r\n",
                "testSampler = RandomSampler(testData)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "source": [
                "trainDataloader = DataLoader(trainData, sampler=trainSampler, batch_size=batch_size)\r\n",
                "valDataloader = DataLoader(valData, sampler=valSampler, batch_size=batch_size)\r\n",
                "trainDataloader = DataLoader(testData, sampler=testSampler, batch_size=batch_size)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "source": [
                "from TransformerModel import Transformer\r\n",
                "\r\n",
                "model = Transformer()\r\n",
                "model = model.to(device = device)\r\n",
                "\r\n",
                "from transformers import AdamW\r\n",
                "optimizer = AdamW(model.parameters(), lr = 1e-5)\r\n",
                "crossEntropy = nn.CrossEntropyLoss()\r\n",
                "epochs = 10"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "source": [
                "def train():\r\n",
                "  \r\n",
                "    model.train()\r\n",
                "\r\n",
                "    total_loss, total_accuracy = 0, 0\r\n",
                "  \r\n",
                "  # empty list to save model predictions\r\n",
                "    total_preds=[]\r\n",
                "  \r\n",
                "  # iterate over batches\r\n",
                "    for step,batch in enumerate(trainDataloader):\r\n",
                "        if step % 50 == 0 and not step == 0:\r\n",
                "          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(trainDataloader)))\r\n",
                "\r\n",
                "    # push the batch to gpu\r\n",
                "        batch = [r.to(device) for r in batch]\r\n",
                "        \r\n",
                "        old_id, new_id, old_mask, new_mask = batch\r\n",
                "        old_id = old_id[:,:-1]\r\n",
                "        new_id = new_id[:,1:]\r\n",
                "        model.zero_grad()\r\n",
                "        tgt_mask = model.get_tgt_mask(32)\r\n",
                "        output = model(old_id, new_id,tgt_mask = tgt_mask,src_pad_mask =  old_mask,tgt_pad_mask = new_mask)\r\n",
                "        loss = crossEntropy(new_id, output)\r\n",
                "        print(loss)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "source": [
                "train()"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "TypeError",
                    "evalue": "forward() got an unexpected keyword argument 'tgt_mask'",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-53-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[1;32m<ipython-input-52-a71fcfdc827e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mtgt_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtgt_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc_pad_mask\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mold_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtgt_pad_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrossEntropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'tgt_mask'"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.8 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "9a30607b245585c54d2df3b0bd75967df9bf62b9525f84187576cad8fa1cff9a"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import torch\r\n",
                "import numpy as np\r\n",
                "from torch import nn\r\n",
                "import pandas as pd\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "from transformers import BertTokenizerFast\r\n",
                "from sklearn.model_selection import train_test_split"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "df = pd.read_csv('train.csv')\r\n",
                "df =df.dropna()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "train_old, temp_old, train_new, temp_new = train_test_split(df['old'], df['new'], \r\n",
                "                                                                    random_state=2018, \r\n",
                "                                                                    test_size=0.3)\r\n",
                "val_old, test_old, val_new, test_new = train_test_split(temp_old, temp_new, \r\n",
                "                                                                random_state=2018, \r\n",
                "                                                                test_size=0.5) "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "device = torch.device('cpu')\r\n",
                "if torch.cuda.is_available():\r\n",
                "    device = torch.device(\"cuda\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "oldTrainTokens = tokenizer.batch_encode_plus(\r\n",
                "    train_old.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "newTrainTokens = tokenizer.batch_encode_plus(\r\n",
                "    train_new.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "oldValTokens = tokenizer.batch_encode_plus(\r\n",
                "    val_old.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "newValTokens = tokenizer.batch_encode_plus(\r\n",
                "    val_new.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "\r\n",
                "oldTestTokens = tokenizer.batch_encode_plus(\r\n",
                "    test_old.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "newTestTokens = tokenizer.batch_encode_plus(\r\n",
                "    test_new.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "totensor = torch.LongTensor(oldTrainTokens['input_ids'])\r\n",
                "tntensor = torch.LongTensor(newTrainTokens['input_ids'])\r\n",
                "\r\n",
                "tomask = torch.LongTensor(oldTrainTokens['attention_mask'])\r\n",
                "tnmask = torch.LongTensor(newTrainTokens['attention_mask'])\r\n",
                "\r\n",
                "votensor = torch.LongTensor(oldValTokens['input_ids'])\r\n",
                "vntensor = torch.LongTensor(newValTokens['input_ids'])\r\n",
                "\r\n",
                "vomask = torch.LongTensor(oldValTokens['attention_mask'])\r\n",
                "vnmask = torch.LongTensor(newValTokens['attention_mask'])\r\n",
                "\r\n",
                "testotensor = torch.LongTensor(oldTestTokens['input_ids'])\r\n",
                "testntensor = torch.LongTensor(newTestTokens['input_ids'])\r\n",
                "\r\n",
                "testomask = torch.LongTensor(oldTestTokens['attention_mask'])\r\n",
                "testnmask = torch.LongTensor(newTestTokens['attention_mask'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\r\n",
                "batch_size = 32\r\n",
                "trainData = TensorDataset(totensor, tntensor, tomask, tnmask)\r\n",
                "valData = TensorDataset(votensor, vntensor, vomask, vnmask)\r\n",
                "testData = TensorDataset(testotensor, testntensor, testomask, testnmask)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "trainSampler = RandomSampler(trainData)\r\n",
                "valSampler = RandomSampler(valData)\r\n",
                "testSampler = RandomSampler(testData)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "trainDataloader = DataLoader(trainData, sampler=trainSampler, batch_size=batch_size)\r\n",
                "valDataloader = DataLoader(valData, sampler=valSampler, batch_size=batch_size)\r\n",
                "trainDataloader = DataLoader(testData, sampler=testSampler, batch_size=batch_size)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "source": [
                "from TransformerModel import Transformer\r\n",
                "model = Transformer(num_heads = 8,num_encoder_layers = 6, num_decoder_layers = 6, dropout_p = 0.1 ,dim_model = 512, num_tokens = 32 )\r\n",
                "model = model.to(device = device)\r\n",
                "\r\n",
                "from transformers import AdamW\r\n",
                "optimizer = AdamW(model.parameters(), lr = 1e-5)\r\n",
                "crossEntropy = nn.CrossEntropyLoss()\r\n",
                "epochs = 10"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "source": [
                "def train():\r\n",
                "  \r\n",
                "    model.train()\r\n",
                "\r\n",
                "    total_loss = 0\r\n",
                "  \r\n",
                "  # empty list to save model predictions\r\n",
                "    total_preds=[]\r\n",
                "  \r\n",
                "  # iterate over batches\r\n",
                "    for step,batch in enumerate(trainDataloader):\r\n",
                "        if step % 50 == 0 and not step == 0:\r\n",
                "          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(trainDataloader)))\r\n",
                "\r\n",
                "    # push the batch to gpu\r\n",
                "        batch = [r.to(device) for r in batch]\r\n",
                "        \r\n",
                "        old_id, new_id, old_mask, new_mask = batch\r\n",
                "        #old_id = old_id[:,:-1]\r\n",
                "        #new_id = new_id[:,1:]\r\n",
                "        print(old_id.size(), new_id.size())\r\n",
                "        model.zero_grad()\r\n",
                "        tgt_mask = model.get_tgt_maska(size = 32)\r\n",
                "        \r\n",
                "        output = model(src = old_id,tgt =  new_id,tgt_mask = tgt_mask,src_pad_mask =  old_mask,tgt_pad_mask = new_mask)\r\n",
                "       \r\n",
                "        \r\n",
                "        #print(output[0], new_id[0])\r\n",
                "        #print('Dim: ', output.size(),new_id.size(), output.dtype, new_id.dtype )\r\n",
                "      \r\n",
                "        \r\n",
                "        loss = crossEntropy(output, new_id)\r\n",
                "        total_loss+=loss\r\n",
                "        loss.backward()\r\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
                "        optimizer.step()\r\n",
                "    avg_loss = total_loss / len(trainDataloader)\r\n",
                "    return avg_loss\r\n",
                "        "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "source": [
                "train()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "torch.Size([32, 32]) torch.Size([32, 32])\n"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "IndexError",
                    "evalue": "Target 101 is out of bounds.",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-44-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[1;32m<ipython-input-43-bc360dd78076>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrossEntropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mtotal_loss\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1121\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2822\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2824\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mIndexError\u001b[0m: Target 101 is out of bounds."
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "source": [
                "criterion = nn.CrossEntropyLoss()\r\n",
                "\r\n",
                "output = torch.randn(10, 120).float()\r\n",
                "target = torch.FloatTensor(10).uniform_(0, 120).long()\r\n",
                "print(output.size())\r\n",
                "print(target.size())\r\n",
                "lossF = criterion(output, target)\r\n",
                "lossF"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "torch.Size([10, 120])\n",
                        "torch.Size([10])\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "tensor(5.3035)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 32
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.8 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "9a30607b245585c54d2df3b0bd75967df9bf62b9525f84187576cad8fa1cff9a"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
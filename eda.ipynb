{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import torch\r\n",
                "import numpy as np\r\n",
                "from torch import nn\r\n",
                "import pandas as pd\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "from transformers import BertTokenizerFast\r\n",
                "from sklearn.model_selection import train_test_split"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "df = pd.read_csv('train.csv')\r\n",
                "df =df.dropna()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "train_old, temp_old, train_new, temp_new = train_test_split(df['old'], df['new'], \r\n",
                "                                                                    random_state=2018, \r\n",
                "                                                                    test_size=0.3)\r\n",
                "val_old, test_old, val_new, test_new = train_test_split(temp_old, temp_new, \r\n",
                "                                                                random_state=2018, \r\n",
                "                                                                test_size=0.5) "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "device = torch.device('cpu')\r\n",
                "if torch.cuda.is_available():\r\n",
                "    device = torch.device(\"cuda\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "oldTrainTokens = tokenizer.batch_encode_plus(\r\n",
                "    train_old.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "newTrainTokens = tokenizer.batch_encode_plus(\r\n",
                "    train_new.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "oldValTokens = tokenizer.batch_encode_plus(\r\n",
                "    val_old.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "newValTokens = tokenizer.batch_encode_plus(\r\n",
                "    val_new.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "\r\n",
                "oldTestTokens = tokenizer.batch_encode_plus(\r\n",
                "    test_old.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n",
                "newTestTokens = tokenizer.batch_encode_plus(\r\n",
                "    test_new.to_list(),\r\n",
                "    max_length = 32,\r\n",
                "    padding = 'max_length',\r\n",
                "    truncation=True\r\n",
                ")\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "totensor = torch.LongTensor(oldTrainTokens['input_ids'])\r\n",
                "tntensor = torch.LongTensor(newTrainTokens['input_ids'])\r\n",
                "\r\n",
                "tomask = torch.LongTensor(oldTrainTokens['attention_mask'])\r\n",
                "tnmask = torch.LongTensor(newTrainTokens['attention_mask'])\r\n",
                "\r\n",
                "votensor = torch.LongTensor(oldValTokens['input_ids'])\r\n",
                "vntensor = torch.LongTensor(newValTokens['input_ids'])\r\n",
                "\r\n",
                "vomask = torch.LongTensor(oldValTokens['attention_mask'])\r\n",
                "vnmask = torch.LongTensor(newValTokens['attention_mask'])\r\n",
                "\r\n",
                "testotensor = torch.LongTensor(oldTestTokens['input_ids'])\r\n",
                "testntensor = torch.LongTensor(newTestTokens['input_ids'])\r\n",
                "\r\n",
                "testomask = torch.LongTensor(oldTestTokens['attention_mask'])\r\n",
                "testnmask = torch.LongTensor(newTestTokens['attention_mask'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "print(torch.max(torch.max(totensor)),torch.max(torch.max(tntensor)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor(29611) tensor(29610)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\r\n",
                "batch_size = 32\r\n",
                "trainData = TensorDataset(totensor, tntensor, tomask, tnmask)\r\n",
                "valData = TensorDataset(votensor, vntensor, vomask, vnmask)\r\n",
                "testData = TensorDataset(testotensor, testntensor, testomask, testnmask)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "trainSampler = RandomSampler(trainData)\r\n",
                "valSampler = RandomSampler(valData)\r\n",
                "testSampler = RandomSampler(testData)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "trainDataloader = DataLoader(trainData, sampler=trainSampler, batch_size=batch_size)\r\n",
                "valDataloader = DataLoader(valData, sampler=valSampler, batch_size=batch_size)\r\n",
                "trainDataloader = DataLoader(testData, sampler=testSampler, batch_size=batch_size)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "from TransformerModel import Transformer\r\n",
                "model = Transformer(num_heads = 8,num_encoder_layers = 6, num_decoder_layers = 6, dropout_p = 0.1 ,dim_model = 512, num_tokens = 32 )\r\n",
                "model = model.to(device = device)\r\n",
                "\r\n",
                "from transformers import AdamW\r\n",
                "optimizer = AdamW(model.parameters(), lr = 1e-5)\r\n",
                "crossEntropy = nn.CrossEntropyLoss()\r\n",
                "epochs = 10"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "def train():\r\n",
                "  \r\n",
                "    model.train()\r\n",
                "\r\n",
                "    total_loss = 0\r\n",
                "  \r\n",
                "  # empty list to save model predictions\r\n",
                "    total_preds=[]\r\n",
                "  \r\n",
                "  # iterate over batches\r\n",
                "    for step,batch in enumerate(trainDataloader):\r\n",
                "        #if step % 5 == 0 and not step == 0:\r\n",
                "        print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(trainDataloader)))\r\n",
                "\r\n",
                "    # push the batch to gpu\r\n",
                "        batch = [r.to(device) for r in batch]\r\n",
                "        \r\n",
                "        old_id, new_id, old_mask, new_mask = batch\r\n",
                "        #old_id = old_id[:,:-1]\r\n",
                "        #new_id = new_id[:,1:]\r\n",
                "        \r\n",
                "        model.zero_grad()\r\n",
                "        tgt_mask = model.get_tgt_maska(size = 32)\r\n",
                "        \r\n",
                "        output = model(src = old_id,tgt =  new_id,tgt_mask = tgt_mask,src_pad_mask =  old_mask,tgt_pad_mask = new_mask)\r\n",
                "       \r\n",
                "        \r\n",
                "        #print(output[0], new_id[0])\r\n",
                "        #print('Dim: ', output.size(),new_id.size(), output.dtype, new_id.dtype )\r\n",
                "        #(32, 32, )\r\n",
                "        output = output.permute(1,2,0)\r\n",
                "        loss = crossEntropy(output, new_id)\r\n",
                "        print(loss)\r\n",
                "        total_loss+=loss\r\n",
                "        loss.backward()\r\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
                "        optimizer.step()\r\n",
                "    avg_loss = total_loss / len(trainDataloader)\r\n",
                "    return avg_loss\r\n",
                "        "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "train()"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-20-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[1;32m<ipython-input-18-843f266e725b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mtgt_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tgt_maska\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtgt\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnew_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtgt_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc_pad_mask\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mold_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtgt_pad_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32mc:\\Users\\psiml\\Documents\\projekat\\TransformerModel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, tgt, tgt_mask, src_pad_mask, tgt_pad_mask)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mtransformer_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc_pad_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtgt_pad_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "criterion = nn.CrossEntropyLoss()\r\n",
                "\r\n",
                "output = torch.randn(10, 120).float()\r\n",
                "target = torch.FloatTensor(10).uniform_(0, 120).long()\r\n",
                "print(output.size())\r\n",
                "print(target.size())\r\n",
                "lossF = criterion(output, target)\r\n",
                "lossF"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "torch.Size([10, 120])\n",
                        "torch.Size([10])\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "tensor(5.1132)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 15
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.8 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "9a30607b245585c54d2df3b0bd75967df9bf62b9525f84187576cad8fa1cff9a"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}